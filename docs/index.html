<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Diorama: Unleashing Zero-shot Single-view 3D Scene Modeling">
  <meta name="keywords" content="Diorama, Zero-shot, Open-world, Single-view, 3D scene modeling">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>Diorama: Unleashing Zero-shot Single-view 3D Scene Modeling</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-G85PZGL346"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-G85PZGL346');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Diorama: Unleashing Zero-shot Single-view 3D Scene Modeling</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://qiruiw.github.io/">Qirui Wu</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="">Denys Iliash</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://dritchie.github.io/">Daniel Ritchie</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://msavva.github.io/">Manolis Savva</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="http://angelxuanchang.github.io/">Angel X. Chang</a><sup>1,3</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Simon Fraser University,</span>
              <span class="author-block"><sup>2</sup>Brown University,</span>
              <span class="author-block"><sup>3</sup>Canada-CIFAR AI Chair, Amii</span>
            </div>
            <!-- <div class="is-size-5 publication-authors">
              <span class="author-block" style="color:#efcc3e">CVPR 2024</span>
            </div> -->

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2411.19492" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://youtu.be/9n9El7c9nAY" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/3dlg-hcvc/diorama"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                <a href="https://huggingface.co/datasets/3dlg-hcvc/r3ds"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data (HuggingFace)</span>
                  </a>
                </span> -->
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <!-- <h2 class="title is-3">Video</h2> -->
          <div class="publication-video">
            <!-- <iframe src="https://www.youtube.com/embed/waI3m7TuyNA?si=HwYPPjeoIE6AkanT" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
            <iframe width="956" height="538" src="https://www.youtube.com/embed/9n9El7c9nAY" title="Diorama: Unleashing Zero-shot Single-view 3D Scene Modeling" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>  
  </section>

  <section class="section">
    <div class="container is-max-desktop">   
      <!-- Abstract. --> 
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <!-- <h2 class="title is-3">Abstract</h2> -->
          <div class="content has-text-justified">
            <p>
              <b>TL;DR</b>: Our work is driven by the question <i>"Is holistic 3D scene modeling from a single-view real-world image possible using foundation models?"</i> To answer it, we present <b>Diorama: a modular zero-shot open-world system that models synthetic holistic 3D scenes given an image and requires no end-to-end training</b>.
            </p>
          </div>
          <div class="container is-max-desktop">
            <div class="column has-text-centered">
              <!-- <img src="./static/images/teaser.webp" class="interpolation-image crop_grey_line" alt="Teaser." / style="max-width: 100%;"> -->
              <div class="crop_grey_line">
                <video autoplay playsinline muted loop >
                  <source src="./static/images/demo.mov">
                </video>
              </div>
            </div>
          </div>
          
        </div>
      </div>
      <!--/ Abstract. -->

      
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">   
      <!-- Abstract. --> 
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Reconstructing structured 3D scenes from RGB images using CAD objects unlocks efficient and compact scene representations that maintain compositionality and interactability. Existing works propose training-heavy methods relying on either expensive yet inaccurate real-world annotations or controllable yet monotonous synthetic data that do not generalize well to unseen objects or domains.
            </p>

            <p>
              We present Diorama, the first zero-shot open-world system that holistically models 3D scenes from single-view RGB observations without requiring end-to-end training or human annotations. We show the feasibility of our approach by decomposing the problem into subtasks and introduce robust, generalizable solutions to each: architecture reconstruction, 3D shape retrieval, object pose estimation, and scene layout optimization. We evaluate our system on both synthetic and real-world data to show we significantly outperform baselines from prior work. We also demonstrate generalization to internet images and the text-to-scene task.
            </p>
          </div>
          <div class="container is-max-desktop">
            <div class="column has-text-centered">
              <!-- <img src="./static/images/teaser.webp" class="interpolation-image crop_grey_line" alt="Teaser." / style="max-width: 100%;"> -->
              <img src="./static/images/teaser.png" class="interpolation-image" alt="teaser"/>
              <!-- <div class="crop_grey_line">
              </div> -->
            </div>
          </div>
          
        </div>
      </div>
      <!--/ Abstract. -->

      
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
        <!-- Results. -->
        <div class="content has-text-justified">
          <h3 class="title is-3">System Overview</h3>
          <!-- <div class="center-container">
          </div> -->
          
          <div class="column has-text-centered">
            <img src="./static/images/pipeline.png" class="interpolation-image" alt="pipeline"/>
          </div>

          <p>
            Our system has two major components: <b>(1) Open-world perception</b> for holistic scene understanding of the input image, including object recognition and localization, depth and normal estimation, architecture reconstruction and scene graph generation (orange box).
            <b>(2) CAD-based scene modeling</b> for assembly of a clean and compact 3D scene representation through CAD model retrieval, 9-DoF pose estimation, and semantic-aware scene layout optimization (green box).
          </p>

          <p>
            As a modular system, its performance can be naturally improved by replacing each individual component with a dedicated approach of better performance. We choose different components based on the principles of open vocabulary, category agnosticism, and robustness to non-exact object matches.
            The reconstructed scenes benefit from certain designs of Diorama, including scene graph for maintaining spatial relationships among objects, shape retrieval for multiple semantically similar arrangements, planar architecture for physically plausible supporting objects, and layout optimization for refining objects poses based on spatial relationships.
          </p>

          <!-- <h4 class="title is-4">R3DS Scenes (inst-colored)
          </h4>
          <p>
            Examples of R3DS scenes colored by object instances, along with paired 360 degree observing videos from synthetic scenes and real scans using the same camera pose.
          </p>
          <div class="crop_grey_line">
            <video autoplay playsinline muted loop >
              <source src="./static/images/scenes_inst_color.mp4">
            </video>
          </div>

          <h4 class="title is-4">R3DS Scenes (model-colored)</h4>
          <p>
            Examples of R3DS scenes colored by annotated CAD models that shows matched object instance sets are one of the main characteristics of R3DS scenes.
          </p>
          <div class="center-container">
            <div class="crop_grey_line">
              <video autoplay playsinline muted loop >
                <source src="./static/images/scenes_model_color.mp4">
              </video>
            </div>
          </div>

          </div> -->

        </div>
        <!--/ Results. -->
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
        <!-- Results. -->
        <div class="content has-text-justified">
          <h3 class="title is-3">Results</h3>
          <!-- <div class="center-container">
          </div> -->

          <p>
            We demonstrate the feasibility of our system on synthetic images for evaluation. And also show generalization to in-the-wild internet images and the text2scene task where an image input is generated from a text prompt.
          </p>

          <h4 class="title is-4">SSDB Results</h4>
          <p>
            Specifically, we evaluate on stanford scene database scenes, which contains highly cluttered arrangements ranging from office desk setups to chemistry laboratories. We show similar semantic arrangements using different retrieved 3D shapes. Refer to the paper for detailed quantitative results.
          </p>
          <div class="column has-text-centered">
            <img src="./static/images/wss_res1.png" class="interpolation-image" alt="wss1"/>
            <img src="./static/images/wss_res2.png" class="interpolation-image" alt="wss2"/>
          </div>
          <!-- <div class="crop_grey_line">
          </div> -->

          <h4 class="title is-4">In-the-wild Results</h4>
          <div class="column has-text-centered">
            <img src="./static/images/wild_res.png" class="interpolation-image" alt="in_the_wild"/>
          </div>

          <h4 class="title is-4">Text-to-Scene Results</h4>
          <div class="column has-text-centered">
            <img src="./static/images/t2s_res.png" class="interpolation-image" alt="text2scene"/>
          </div>

        </div>
        <!--/ Results. -->
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@article{wu2024diorama,
  title={Diorama: Unleashing Zero-shot Single-view 3D Scene Modeling},
  author={Wu, Qirui and Iliash, Denys and Ritchie, Daniel and Savva, Manolis and Chang, Angel X},
  journal={arXiv preprint arXiv:2411.19492},
  year={2024}
}
      </code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
              The template is borrowed from <a href="https://nerfies.github.io/">Nerfies</a>.
              Please check out their great work if you find it helpful as well.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>